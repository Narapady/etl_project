[2022-08-11 05:54:19,373] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: ETL_DAG_V1.Stage_data manual__2022-08-11T00:37:41.769140+00:00 [queued]>
[2022-08-11 05:54:19,382] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: ETL_DAG_V1.Stage_data manual__2022-08-11T00:37:41.769140+00:00 [queued]>
[2022-08-11 05:54:19,383] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-08-11 05:54:19,385] {taskinstance.py:1377} INFO - Starting attempt 1 of 6
[2022-08-11 05:54:19,386] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-08-11 05:54:19,399] {taskinstance.py:1397} INFO - Executing <Task(PythonOperator): Stage_data> on 2022-08-11 00:37:41.769140+00:00
[2022-08-11 05:54:19,415] {standard_task_runner.py:52} INFO - Started process 17744 to run task
[2022-08-11 05:54:19,430] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'ETL_DAG_V1', 'Stage_data', 'manual__2022-08-11T00:37:41.769140+00:00', '--job-id', '186', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmp12ftiqib', '--error-file', '/tmp/tmpyn7gf53q']
[2022-08-11 05:54:19,433] {standard_task_runner.py:80} INFO - Job 186: Subtask Stage_data
[2022-08-11 05:54:19,528] {task_command.py:371} INFO - Running <TaskInstance: ETL_DAG_V1.Stage_data manual__2022-08-11T00:37:41.769140+00:00 [running]> on host c9fcec21ee59
[2022-08-11 05:54:19,618] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=narapady
AIRFLOW_CTX_DAG_ID=ETL_DAG_V1
AIRFLOW_CTX_TASK_ID=Stage_data
AIRFLOW_CTX_EXECUTION_DATE=2022-08-11T00:37:41.769140+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-08-11T00:37:41.769140+00:00
[2022-08-11 05:54:22,732] {logging_mixin.py:115} INFO - Successfully loaded Obesity_GDP_PanelData-staged.csv to s3-bucket-staged
[2022-08-11 05:54:44,315] {logging_mixin.py:115} INFO - Successfully loaded obesity-staged.csv to s3-bucket-staged
[2022-08-11 05:54:49,610] {logging_mixin.py:115} INFO - Successfully loaded fast-food-staged.csv to s3-bucket-staged
[2022-08-11 05:55:00,732] {logging_mixin.py:115} INFO - Successfully loaded food-consumption-estimates-staged.csv to s3-bucket-staged
[2022-08-11 05:55:05,458] {local_task_job.py:221} WARNING - State of this instance has been externally set to removed. Terminating instance.
[2022-08-11 05:55:05,469] {process_utils.py:129} INFO - Sending Signals.SIGTERM to group 17744. PIDs of all processes in the group: [17744]
[2022-08-11 05:55:05,470] {process_utils.py:80} INFO - Sending the signal Signals.SIGTERM to group 17744
[2022-08-11 05:55:05,472] {taskinstance.py:1561} ERROR - Received SIGTERM. Terminating subprocesses.
[2022-08-11 05:55:05,473] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/httpsession.py", line 414, in send
    chunked=self._chunked(request.headers),
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 424, in connect
    tls_in_tls=tls_in_tls,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 450, in ssl_wrap_socket
    sock, context, tls_in_tls, server_hostname=server_hostname
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/local/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/usr/local/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/usr/local/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1563, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/stage/stager.py", line 177, in run
    stager.stage()
  File "/opt/airflow/dags/stage/stager.py", line 167, in stage
    staging_fn(self.s3, dir)
  File "/opt/airflow/dags/stage/stager.py", line 38, in stage_foodnutrient_estimates
    df = s3.load_df(src_bucket, f"{dirname}/{file}", "csv")
  File "/opt/airflow/dags/storage/s3.py", line 31, in load_df
    return pd.read_csv(smart_open(path))
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/smart_open_lib.py", line 503, in smart_open
    return open(**locals())
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/smart_open_lib.py", line 224, in open
    binary = _open_binary_stream(uri, binary_mode, transport_params)
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/smart_open_lib.py", line 400, in _open_binary_stream
    fobj = submodule.open_uri(uri, mode, transport_params)
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/s3.py", line 224, in open_uri
    return open(parsed_uri['bucket_id'], parsed_uri['key_id'], mode, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/s3.py", line 298, in open
    client_kwargs=client_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/s3.py", line 574, in __init__
    self.seek(0)
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/s3.py", line 666, in seek
    self._current_pos = self._raw_reader.seek(offset, whence)
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/s3.py", line 417, in seek
    self._open_body(start, stop)
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/s3.py", line 443, in _open_body
    range_string,
  File "/home/airflow/.local/lib/python3.7/site-packages/smart_open/s3.py", line 330, in _get
    return client.get_object(Bucket=bucket, Key=key, Range=range_string)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 395, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 712, in _make_api_call
    operation_model, request_dict, request_context)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 731, in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 107, in make_request
    return self._send_request(request_dict, operation_model)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 184, in _send_request
    success_response, exception):
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 308, in _needs_retry
    caught_exception=caught_exception, request_dict=request_dict)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 357, in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 228, in emit
    return self._emit(event_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/hooks.py", line 211, in _emit
    response = handler(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 192, in __call__
    if self._checker(**checker_kwargs):
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 266, in __call__
    caught_exception)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 284, in _should_retry
    return self._checker(attempt_number, response, caught_exception)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 332, in __call__
    caught_exception)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 232, in __call__
    attempt_number, caught_exception)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/retryhandler.py", line 374, in _check_caught_exception
    raise caught_exception
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 249, in _do_get_response
    http_response = self._send(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/endpoint.py", line 321, in _send
    return self.http_session.send(request)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/httpsession.py", line 450, in send
    raise HTTPClientError(error=e)
botocore.exceptions.HTTPClientError: An HTTP Client raised an unhandled exception: Task received SIGTERM signal
[2022-08-11 05:55:05,494] {taskinstance.py:1420} INFO - Marking task as UP_FOR_RETRY. dag_id=ETL_DAG_V1, task_id=Stage_data, execution_date=20220811T003741, start_date=20220811T055419, end_date=20220811T055505
[2022-08-11 05:55:05,511] {standard_task_runner.py:97} ERROR - Failed to execute job 186 for task Stage_data (An HTTP Client raised an unhandled exception: Task received SIGTERM signal; 17744)
[2022-08-11 05:55:05,564] {process_utils.py:75} INFO - Process psutil.Process(pid=17744, status='terminated', exitcode=1, started='05:54:18') (17744) terminated with exit code 1
